import re
from bs4 import BeautifulSoup, NavigableString
import json
from minify_html import minify

# The magic needed to translate the HTML output of a standard Confluence instance (Data Center license)
# into Outline's JSON format.

#TODO postprocess: there must not be any text tag outside of a paragaph or heading.
# -> implement wrapping!
#TODO implement text leaf merging!

# Removes superflous HTML and gives us a dict of attachments
def clean_html(soup):
	attachments = {}
	# Extracts the attachment list for further processing
	attached = soup.find(id="attachments")
	if attached:
		attached = attached.parent.parent.extract()
		print(attached)
		attached = attached.find(class_="greybox")
		attached = attached.find_all("a")

		for attachment in attached:
			key = attachment["href"].split("/")[-1]
			attachments[key] = ""
			attachment.decompose()

	breadcrumbs = soup.find(id="main-header")
	breadcrumbs.extract()

	# Format Confluence export metadata nicely and remove Atlassian link
	footer = soup.find(id="footer")
	footer.find(id="footer-logo").decompose()
	footer.section.p.unwrap()
	footer.section.unwrap()
	footer.smooth()
	footer = footer.extract()
	metadata = soup.find(class_="page-metadata")
	if metadata.span:
		metadata.span.unwrap()
	if metadata.span:
		metadata.span.unwrap()
	metadata.smooth()
	metadata = metadata.wrap(soup.new_tag('em'))
	metadata.append(footer)
	metadata = metadata.wrap(soup.new_tag('p'))


	# Tags that fuck up any given import
	# Includes the following:
	# - Remove the profile-full tables to resolve display issues
	#   These are empty anyways, so it's fine
	# - profile picture for vcards - not really necessary to display
	#   They're more of eye candy than important content
	# - Remove certain divs
	bad_tags = {
		"span": ["aui-avatar"],
		"div": ["update-item-icon", "update-item-profile", "more-link-container"],
		"table": ["profile-full"],
	}

	for name, classes in bad_tags.items():
		for clazz in classes:
			bad_tags = soup.find_all(name=name, class_=clazz)
			for bad_tag in bad_tags:
				bad_tag.decompose()

	# Remove tiny Jira icons
	jira_keys = soup.find_all(class_="jira-issue-key")
	for jira_key in jira_keys:
		if jira_key.img:
			jira_key.img.decompose()

	# Fixes emojis inserted via :<emoji_name>:
	# I like this code:
	# - the unicode hex is given in an HTML attribute
	# - it's a simple conversion
	emojis = soup.find_all(class_="emoticon")
	for emoji in emojis:
		emoji.replace_with(chr(int(emoji["data-emoji-id"], 16)))

	# Unwrap unnecessary divs and spans
	dive = soup.find_all('div')
	for div in dive:
		if 'class' in div.attrs.keys():
			#print(div['class'])
			if 'confluence-information-macro-information' in div['class']:
				div.name = 'info'
				continue
			elif 'confluence-information-macro-tip' in div['class']:
				div.name = 'tip'
				continue
			elif 'confluence-information-macro-note' in div['class']:
				div.name = 'note'
				continue
			elif 'confluence-information-macro-warning' in div['class']:
				div.name = 'warning'
				continue
		div.unwrap()
		div.smooth()

	spans = soup.find_all('span')
	for span in spans:
		span.unwrap()
		span.smooth()

	# We need the attachments later, so let's pass them to the rest
	return attachments

def create_json(tag):
	# Just in case
	if not tag:
		return None

	if type(tag) is NavigableString:
		if tag.string == '':
			return None
		return {"type": "text", "text": tag.string}

	if tag.name == 'br':
		return {"type": "br"}

	if tag.name == 'img':
		return {"type": "image", "attrs": {"src": tag['src'], "alt": tag['alt'] if 'alt' in tag.attrs and tag['alt'] != '' else None}}

	# This only handles text links properly, and doesn't apply inner formatting
	# That is intentional - Outline can't handle images as link "text", and changing the appearance of a link isn't that important
	if tag.name == 'a':
		return {"type": "text", "marks": [{"type": "link", "attrs": [{"href": tag['href'].strip()}]}], "text": tag.get_text(strip=True)}

	contents = []
	tag_type = tag.name
	simple_type_map = {
		'body': 'doc',
		'p': 'paragraph',
		'li': 'list_item',
		'h1': 'heading',
		'h2': 'heading',
		'h3': 'heading',
		'h4': 'heading',
		'li': 'list_item',
		'ul': 'bullet_list',
		'button': 'paragraph', # Buttons wouldn't work so we make them a paragraph
	}
	attrs = {}

	tag_type = simple_type_map[tag.name] if tag.name in simple_type_map.keys() else tag.name

	if tag.name == 'ul' and 'data-inline-tasks-content-id' in tag.attrs:
		tag_type = 'checkbox_list'

	if tag.name in ['h1', 'h2', 'h3', 'h4']:
		attrs['level'] = int(tag.name[1])

	if tag.name in ['th', 'td']:
		attrs['colspan'] = int(tag['colspan']) if 'colspan' in tag.attrs else 1
		attrs['rowspan'] = int(tag['rowspan']) if 'rowspan' in tag.attrs else 1

		# Known issue: This will set alignment to the first specified one, not the last.
		# Since this HTML is generated by Confluence, we assume it not to set two different alignments
		# on the same table cell
		if 'style' in tag.attrs:
			align = re.match(r'text-align: ([a-zA-Z]+);', tag['style'])
			if align.group(1):
				align = align.group(1)
			else:
				align = None
		else:
			align = None # Set default null/None
		attrs['alignment'] = align

	for child in tag.children:
		child_json = create_json(child)
		if child_json:
			contents.append(child_json)

	if tag_type == 'paragraph' and len(contents) == 0:
		return None

	parsed = {"type": tag_type, "content": contents}

	if tag.name == 'li' and 'data-inline-task-id' in tag.attrs:
		checked = ("class" in tag.attrs and "checked" in tag['class'])
		parsed = {"type": "checkbox_item", "checked": checked, "content": [{"type": "paragraph", "content": contents}]}

	if len(attrs.keys()) > 0:
		parsed.update({"attrs": attrs})
	return parsed

def merge_textleaves(json):
	pass

def unwrap_marked_text(json):
	pass

def html_to_json(html_content):
	html_content = minify(html_content)
	soup = BeautifulSoup(html_content, 'lxml')
	attachments = clean_html(soup)
	return create_json(soup.find('body')), attachments

if __name__ == '__main__':
	filec = open("test/test4.html", "r").read()
	c, _ = html_to_json(filec)
	open("test/test4.json", "w").write(json.dumps(c))
